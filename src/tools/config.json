{
  "openai_call": {
    "prompt": "- self.openai_call(prompt, ?temperature=0.4, ?max_tokens=200) -> str: runs an arbitrary LLM completion. I must use f-strings to pass values and context;\nI must use this ONLY when I need to handle dynamic texts and nlp processes. To handle information in my memory, prompt or context it's just I write a string as a LLM, using all knowledge that I've learned from the Corpus of my training. I must use openai_call when I don't know the content of a string/text and must examine it without knowing its content. I.e I can use it to find specific info in a text, to edit some text, to synthetize new text based on a prompt or f-string. openai_call doesn't have internet access nor can access/write files on the computer. It can only return a text response based on a prompt that might be a f-string.",
    "enabled": true
  },
  "execution_agent": {
    "prompt": "- self.execution_agent(task:str) -> str; I must use this if I need to run arbitrary code based on a dinamic value (i.e a openai response, a memory call or even another execution_agent);\nI must analyze what to do and how to do.",
    "enabled": true
  },
  "count_tokens": {
    "prompt": "- self.count_tokens(text:str) -> int; to count the ammount of tokens of a given string, I need to use this when handling with large files/data, and when I don't know the size of the data;",
    "enabled": true
  },
  "process_large_text": {
    "prompt": "- self.process_large_text(text:str, instruction:str, ?max_output_length=1000:int, ?split_text=None:function)->str, it's like openai_call but for big files/texts, it splits the text in chunks given the specific split_text function (If I not pass any split_text or pass None, the text will be splitted in chunks of 1000 chars each. Either way I must create a function to each case, sometimes it can be useful to just split using the chars count, but sometimes I might use some specific function to parse css, html, programming languages...)\n\n\nsplit_text function example:\ndef split_text(text, max_length):\n    # Split text into chunks of length at most max_length\n    chunks = []\n    while len(text) > 0:\n        chunk = text[:max_length]\n        text = text[max_length:]\n        chunks.append(chunk)\n    return chunks\n",
    "enabled": false
  },
  "get_serp_query": {
    "prompt": "- self.get_serp_query_result(query: str, n: int) -> list of lists on format [['snippet', 'link'], ['snippet', 'link']], return the n most relevant results of a given query using SerpAPI (GoogleSearch);",
    "enabled": true
  },
  "memory_agent": {
    "prompt": "- self.memory_agent(caller:str, content:str, goal:goal) - str or True if there's no return string. This agent can handle memory I/O and can create severals types of memories. Avoid using this;\n",
    "enabled": false
  },
  "erpnext_get_records_list": {
    "prompt": "- self.erpnext_get_records_list(doctype:str, ?fields:list, ?filters:list, ?order_by:str, ?limit_start:int, ?limit_page_length:int, ?parent:str, ?or_filters:list) -> list[dict] - Returns a list of records by filters, fields, ordering and limit",
    "enabled": true
  },
  "erpnext_insert_doc": {
    "prompt": "- self.erpnext_insert_doc(doc:dict) -> dict - Inserts a new doc from a dict into ERPNext database, the target doctype should be passed as key 'doctype'",
    "enabled": true
  }
}

